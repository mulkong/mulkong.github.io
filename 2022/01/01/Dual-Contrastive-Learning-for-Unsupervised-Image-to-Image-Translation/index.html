<!DOCTYPE html>
<html lang="ko">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.0/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mulkong.github.io","root":"/","scheme":"Muse","version":"8.0.1","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}};
  </script>

  <meta name="description" content="이번 포스팅은 티스토리에서 깃블로그로 이사 후 티스토리에 정리했던 내용에서 내용을 추가해서 작성한 글 입니다. 이전 글은 Tistory에서 보실 수 있습니다.">
<meta property="og:type" content="article">
<meta property="og:title" content="Dual Contrastive Learning for Unsupervised Image-to-Image Translation">
<meta property="og:url" content="http://mulkong.github.io/2022/01/01/Dual-Contrastive-Learning-for-Unsupervised-Image-to-Image-Translation/index.html">
<meta property="og:site_name" content="Mulkong DeepLearning">
<meta property="og:description" content="이번 포스팅은 티스토리에서 깃블로그로 이사 후 티스토리에 정리했던 내용에서 내용을 추가해서 작성한 글 입니다. 이전 글은 Tistory에서 보실 수 있습니다.">
<meta property="og:locale" content="ko_KR">
<meta property="og:image" content="http://mulkong.github.io/images/post_images/post0006/figure0003.png">
<meta property="og:image" content="http://mulkong.github.io/images/post_images/post0006/figure0001.png">
<meta property="og:image" content="http://mulkong.github.io/images/post_images/post0006/figure0002.gif">
<meta property="og:image" content="http://mulkong.github.io/images/post_images/post0006/figure0003.png">
<meta property="article:published_time" content="2022-01-01T09:59:13.000Z">
<meta property="article:modified_time" content="2022-04-17T09:49:51.989Z">
<meta property="article:author" content="mulkong">
<meta property="article:tag" content="GAN">
<meta property="article:tag" content="Vision">
<meta property="article:tag" content="Autoencoder">
<meta property="article:tag" content="Uncertainty">
<meta property="article:tag" content="Unsupervised Learning">
<meta property="article:tag" content="paper review">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://mulkong.github.io/images/post_images/post0006/figure0003.png">


<link rel="canonical" href="http://mulkong.github.io/2022/01/01/Dual-Contrastive-Learning-for-Unsupervised-Image-to-Image-Translation/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'ko'
  };
</script>

  <title>Dual Contrastive Learning for Unsupervised Image-to-Image Translation | Mulkong DeepLearning</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Mulkong DeepLearning</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">딥러닝 정리 블로그</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>홈</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>태그</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>카테고리</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>아카이브</a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          목차
        </li>
        <li class="sidebar-nav-overview">
          흝어보기
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Abstract"><span class="nav-number">1.</span> <span class="nav-text">Abstract</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction"><span class="nav-number">2.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Cycle-consistency"><span class="nav-number">2.1.</span> <span class="nav-text">Cycle consistency</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Contrastive-Learning%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-Image-to-Image-Translation"><span class="nav-number">2.2.</span> <span class="nav-text">Contrastive Learning을 이용한 Image-to-Image Translation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DCLGAN"><span class="nav-number">2.3.</span> <span class="nav-text">DCLGAN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%EC%A0%95%EB%A6%AC"><span class="nav-number">2.4.</span> <span class="nav-text">정리</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CycleGAN"><span class="nav-number">2.4.1.</span> <span class="nav-text">CycleGAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CUT"><span class="nav-number">2.4.2.</span> <span class="nav-text">CUT</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Related-Work"><span class="nav-number">3.</span> <span class="nav-text">Related Work</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Supervised-methods"><span class="nav-number">3.1.</span> <span class="nav-text">Supervised methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Pix2Pix"><span class="nav-number">3.1.1.</span> <span class="nav-text">Pix2Pix</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pix2PixHD"><span class="nav-number">3.1.2.</span> <span class="nav-text">Pix2PixHD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SPADE"><span class="nav-number">3.1.3.</span> <span class="nav-text">SPADE</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Unsupervised-methods"><span class="nav-number">3.2.</span> <span class="nav-text">Unsupervised methods</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#MUNIT"><span class="nav-number">3.2.1.</span> <span class="nav-text">MUNIT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DRIT"><span class="nav-number">3.2.2.</span> <span class="nav-text">DRIT</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#StarGAN"><span class="nav-number">3.2.3.</span> <span class="nav-text">StarGAN</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Break-the-cycle"><span class="nav-number">3.3.</span> <span class="nav-text">Break the cycle</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CycleGAN-1"><span class="nav-number">3.3.1.</span> <span class="nav-text">CycleGAN</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CouncilGAN"><span class="nav-number">3.3.2.</span> <span class="nav-text">CouncilGAN</span></a></li></ol></li></ol></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">mulkong</p>
  <div class="site-description" itemprop="description">공부한 내용을 바탕으로 정리한 기술블로그 입니다.</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">포스트</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">카테고리</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">태그</span>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="ko">
    <link itemprop="mainEntityOfPage" href="http://mulkong.github.io/2022/01/01/Dual-Contrastive-Learning-for-Unsupervised-Image-to-Image-Translation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="mulkong">
      <meta itemprop="description" content="공부한 내용을 바탕으로 정리한 기술블로그 입니다.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mulkong DeepLearning">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Dual Contrastive Learning for Unsupervised Image-to-Image Translation
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">작성일</span>

      <time title="Post created: 2022-01-01 18:59:13" itemprop="dateCreated datePublished" datetime="2022-01-01T18:59:13+09:00">2022-01-01</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Updated at: 2022-04-17 18:49:51" itemprop="dateModified" datetime="2022-04-17T18:49:51+09:00">2022-04-17</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/GAN/" itemprop="url" rel="index"><span itemprop="name">GAN</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <hr>
<ul>
<li>이번 포스팅은 티스토리에서 깃블로그로 이사 후 티스토리에 정리했던 내용에서 내용을 추가해서 작성한 글 입니다. 이전 글은 <a target="_blank" rel="noopener" href="https://sensibilityit.tistory.com/522">Tistory</a>에서 보실 수 있습니다.</li>
</ul>
<hr>
<p><img src="/images/post_images/post0006/figure0003.png"> <center></center></p>
<a id="more"></a>

<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><hr>
<p><strong>Unsupervised image-to-image translation개념</strong><br>Unsupervised image-to-image translation tasks는 unpaired train data에서 source domain X와 target domain Y간의 mapping이 되는 지점을 찾는 것을 목표로 하는 task 입니다.</p>
<p><strong>CUT(Contrastive Learning for unpaired image-to-image Translation)</strong><br>Contrastive Learning for unpaired image-to-image Translation은 두개의 도메인 (X, Y) 모두에 대해 하나의 Encoder만 사용하여 입력, 출력 패치(patch)의 mutual information을 최대화 하여 unsupervised image-to-image translation을 모델링 하는 SOTA 결과를 제공합니다.</p>
<p><strong>제안한 방법</strong><br>본 논문에서는 unpaired data간의 효율적인 매핑을 위해 contrastive learning, dual learning setting에 기반한 새로운 학습 방법을 제안합니다.</p>
<p><strong>mode collapse 문제 해결</strong><br>cycle consistency loss의 문제점들을 해결 하기 위해 self-supervised representation learning 분야에서 multiple views of the data 간의 contrastive learning을 이용한 CUT가 SOTA을 달성했지만 mode collapse 문제가 발생 합니다.</p>
<p>🗣 DCLGAN은 데이터 도메인에 따라 mode collapse가 발생할 수 있다는 문제점이 존재하여 이를 해결하기 위해 DCLGAN의 변형인 SimDCL도 논문에서 소개를 하고 있습니다. </p>
<p>이 논문에서 제안한 방법으로 mode collapse문제를 효율적으로 해결합니다.</p>
<ul>
<li>CUT: 1개의 Encoder 사용, 데이터에 따라 mode collapse 문제 발생</li>
<li>DCLGAN: 2개의 Encoder 사용, mode collapse 문제를 효율적으로 해결</li>
</ul>
<p><strong>결론</strong><br>image-to-image translation tasks에서 extensive ablation study을 다른 네트워크들에 비해 본 논문에서 제안한 접근 방식이 효과적이라는 것을 본 논문에서 입증하고 있습니다.</p>
<p>끝으로, unsupervised learning과 supervised learning 방법 사이의 격차를 효율적으로 줄일 수 있음을 보여주고 있습니다.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><hr>
<p>image-to-image translation task는 이미지를 한 도메인에서 다른 도메인으로 변환하는 것을 목표로 합니다. 가장 일반적으로 사용하고 있는 방법은 GAN을 기반으로 하는 방법입니다.</p>
<p>GAN이 발전하게 된 이유중 하나는 adversarial loss를 사용한점 입니다. 하지만 adversarial loss를 unpaired unsupervised image-to-image translation에 사용하여 발생되는 문제점은 adversarial loss가 underconstrained 하다는 점 입니다.</p>
<p>🗣 <strong><em>adversarial loss가 underconstrained 하다면?</em></strong><br>💡 <em>두 도메인(X, Y) 사이에 여러개의 매핑이 존재하게 되어 네트워크 학습이 불안정하게 이루어집니다.</em></p>
<p>그래서 위와 같은 문제를 해결하기 위해 unpaired unsupervised image-to-image translation 에서는 cycle consistency을 사용하여 adversarial loss만 사용했을때 발생되는 문제점을 해결했습니다.</p>
<h2 id="Cycle-consistency"><a href="#Cycle-consistency" class="headerlink" title="Cycle consistency"></a>Cycle consistency</h2><p>cycle consistency loss는 *(그림 1)*처럼target Domain ➡️ source Domain으로 역방향 매핑을 학습할 때 사용하는 loss 입니다.</p>
<p>🗣 <strong><em>역방향 매핑을 학습한다는 의미는?</em></strong><br>💡 <em>입력된 이미지와 재구성된 이미지가 얼마나 동일하게 만들어 지는지를 학습하는 의미이며 cycle consistency loss가 그 차이를 측정하며 학습을 하게 됩니다.</em></p>
<p><img src="/images/post_images/post0006/figure0001.png"> <center><em>(그림 1). Cycle consistency loss</em></center></p>
<p>하지만 cycle consistency을 사용할 때 약간의 가정과 제약이 있습니다.</p>
<p>📌 <strong>cycle consistency의 가정</strong></p>
<ul>
<li>변환된 이미지는 target domain과 유사한 texture information을 가지므로 geometry 변경이 불가하다는 것을 가정으로 두고 cycle consistency를 사용합니다.</li>
<li>두 도메인 (X, Y) 간의 관계가 bijection 되도록 즉, 1:1 대응이 되도록 합니다.</li>
</ul>
<p>📌 <strong>cycle consistency의 제약</strong></p>
<ul>
<li>그로 인해 정확도 손실로 인해 재구성 과정이 제한되므로재구성 이미지의 diversity가 감소하게 됩니다.</li>
</ul>
<p>그래서 이러한 제약을 해결하기 위해 Contrastive Learning을 이용한 연구가 등장을 하게 되었습니다.</p>
<h2 id="Contrastive-Learning을-이용한-Image-to-Image-Translation"><a href="#Contrastive-Learning을-이용한-Image-to-Image-Translation" class="headerlink" title="Contrastive Learning을 이용한 Image-to-Image Translation"></a>Contrastive Learning을 이용한 Image-to-Image Translation</h2><p>cycle consistency loss는 재구성 이미지의 diversity가 감소하게 되는 등의 제약들이 발견되었습니다. 따라서 이를 해결하기 위해self-supervised representation learning 분야에서 multiple views of the data 간의 contrastive learning 방법이 이루어 졌습니다.</p>
<p>이 방법이 기존 cycle consistency loss을 사용한 방법의 제약을 효율적으로 해소함을 보여줌과 동시에 SOTA를 달성하게 되었습니다.</p>
<p>가장 최근에 나온 논문 중 대표적인 논문으로<code>CUT(Contrastive Learning for Unpaired Image-to-Image Translation)</code>이 있습니다. CUT는 <code>unpaired image-to-image translation taks에서 contrastive learning 방식이 효율적</code>이라는 것을 보여주었으며, <code>patch-based multi-layer PatchNCE loss</code>을 사용하여 <code>unpaired image-to-image translation을 위한 Contrastive Learning을 도입하여 입력 및 출력 이미지의 패치간의 mutual information을 최대화 하는 방향으로 학습</code>이 이루어지게 됩니다.</p>
<p>하지만 SOTA를 찍은CUT도 문제점이 보였습니다. 그 문제점은 바로 아이디어는 좋았지만 <code>두 도메인 (X, Y) 사이의 domain gap을 효율적으로 포착하지 못하여 충분히 성능을 끌어올리지 못하고 있다는 점</code> 입니다.</p>
<p>🗣 <strong><em>그럼, 왜 성능을 충분히 끌어 올리지 못했을까요?</em></strong><br>💡 <em>그 이유는 바로 CUT에서 사용한 아키텍처의 특정 부분의 디자인을 잘못 선택해서 성능이 떨어지게 되었습니다.</em></p>
<p>domain gap을 효율적으로 포착하기 위해서는 도메인 수 만큼 임베딩이 사용되어야 합니다. 하지만 CUT는 하나의 임베딩이 사용되어 성능을 제한하고 있다고 본 논문에서 주장을 하고 있습니다.</p>
<p>그래서 본 논문에서는 cycle-consistency의 제약을 피하고, domain gap을 효율적으로 포착할 수 있도록 한개 이상의 임베딩을 사용하고, contrastive learning 방법을 더욱 활용한 DCLGAN을 제안합니다.</p>
<h2 id="DCLGAN"><a href="#DCLGAN" class="headerlink" title="DCLGAN"></a>DCLGAN</h2><hr>
<p><img src="/images/post_images/post0006/figure0002.gif"> <center><em>(그림 2). Contrastive Learning for Unpaired Image-to-Image Translation(CUT) 논문의 Patch-wise Contrastive Learning for one-sided translation</em></center></p>
<p>📌 <strong>목표</strong><br>DCLGAN의 목표는 별도의 임베딩을 사용하여 입력 및 출력 이미지 패치의 상관관계를 학습하여 mutual information을 극대화 하는 것을 목표로 합니다.</p>
<p>📌 <strong>학습 방법</strong><br>DCLGAN은 CUT의 성능을 제한시킨 디자인인 1개의 임베딩을 사용하는 점을 개선시켜 서로 다른 도메인에 서로 다른 Encoder 및 projection heads를 사용함으로써 두 도메인 간의 접점이 되는 부분을 극대화 시키기 위한 1개 이상의 임베딩을 학습합니다.</p>
<p>📌 <strong>발견한점</strong></p>
<ul>
<li>CUT과 달리 DCLGAN의 학습 방법은 dual learning 방식 입니다. 이 방식이 오히려 학습을 안정화 시키는데 도움이 된다고 합니다.</li>
<li>또한 CUT에서 사용한 PatchNCE loss에서 RGB pixel을 제거하는 것이 학습하는대에 있어 도움이 될 수 있음을 발견했습니다.</li>
<li>geometrical structure에 대한 제약이 없는 경우에는 cycle-consistency가 불필요 하다는 점도 발견했습니다.</li>
<li>DCLGAN은 데이터 도메인에 따라 mode collapse가 발생될 수 있지만 그 변형인 SimDCL은 mode collapse를 방지하는데 효과적인 점을 발견했습니다.</li>
</ul>
<p><img src="/images/post_images/post0006/figure0003.png"> <center><em>(그림 3). DCLGAN architecture</em></center></p>
<h2 id="정리"><a href="#정리" class="headerlink" title="정리"></a>정리</h2><hr>
<p>본 눈문은 CycleGAN과 CUT의 한계를 극복할 수 있는 새로움 프레임 워크와 변형 네트워크를 제시하고 있습니다.</p>
<h3 id="CycleGAN"><a href="#CycleGAN" class="headerlink" title="CycleGAN"></a>CycleGAN</h3><p>cycle consistency으로 발생하는 단점.</p>
<h3 id="CUT"><a href="#CUT" class="headerlink" title="CUT"></a>CUT</h3><p>contrastive learning의 효율성을 보여주었지만 한개의 임베딩을 사용해서 domain gap을 효율적으로 포착하지 못할 수 있다는 한계점.<br>또한 여러가지 다양한 실험을 통해 SOTA에 비해 본 논문에서 제안한 방식이 훨씬 효과적이라는 점을 입증하게 되었으며, self-supervised learning 분야에서 contrastive learning 방법이 그랬던것 처럼 unsupervised and supervised learning 방법 사이의 격차를 성공적으로 좁힐 수 있다는 점을 보여주고 있습니다.</p>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><hr>
<h2 id="Supervised-methods"><a href="#Supervised-methods" class="headerlink" title="Supervised methods"></a>Supervised methods</h2><p>📌 관련 논문: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.07004">Pix2Pix</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1711.11585.pdf">Pix2PixHD</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1903.07291">SPADE</a></p>
<h3 id="Pix2Pix"><a href="#Pix2Pix" class="headerlink" title="Pix2Pix"></a>Pix2Pix</h3><p>general methods만 사용하여 여러개의 image-to-image translation tasks을 지원하는 작업에 구애받지 않는 image translation을 처음 수행한 논문 입니다.</p>
<h3 id="Pix2PixHD"><a href="#Pix2PixHD" class="headerlink" title="Pix2PixHD"></a>Pix2PixHD</h3><p>기존 Pix2Pix 논문에서 확장된 방법으로, 고해상도 이미지를 합성할 수 있는 방법 입니다.</p>
<h3 id="SPADE"><a href="#SPADE" class="headerlink" title="SPADE"></a>SPADE</h3><p>생성된 이미지의 품질을 더욱 향상 시키기 위해 spatially-adaptive normalization layer을 도입한 논문입니다.<br>😱 단점: supervised 접근 방법은 학습을 위해 paired data가 필요합니다.</p>
<h2 id="Unsupervised-methods"><a href="#Unsupervised-methods" class="headerlink" title="Unsupervised methods"></a>Unsupervised methods</h2><p>📌 관련 논문: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1804.04732">MUNIT</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1808.00948">DRIT</a>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1711.09020">StarGAN</a><br>비지도 학습 방법은 주로 shared latent space, cycle-consistency assumption을 가정을 두고 있습니다.</p>
<h3 id="MUNIT"><a href="#MUNIT" class="headerlink" title="MUNIT"></a>MUNIT</h3><p>latent space을 style code &amp; content code로 분리하여 domain-specific features를 분리하는 특징이 있는 논문 입니다.</p>
<h3 id="DRIT"><a href="#DRIT" class="headerlink" title="DRIT"></a>DRIT</h3><p>domain-specific attribute space and shared information을 포착하는 content space을 포함한 두 space에서 이미지 임베딩을 하는 논문 입니다.</p>
<h3 id="StarGAN"><a href="#StarGAN" class="headerlink" title="StarGAN"></a>StarGAN</h3><p>대표적인 multi domain image-to-image translation 으로, unified model architecture을 사용하여 여러 도메인에서 이미지를 translation 하는 논문 입니다.</p>
<h2 id="Break-the-cycle"><a href="#Break-the-cycle" class="headerlink" title="Break the cycle"></a>Break the cycle</h2><p>📌 관련 논문: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.10593">CycleGAN</a>, <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Nizan_Breaking_the_Cycle_-_Colleagues_Are_All_You_Need_CVPR_2020_paper.pdf">CouncilGAN</a>, <a target="_blank" rel="noopener" href="https://papers.nips.cc/paper/2017/file/59b90e1005a220e2ebc542eb9d950b1e-Paper.pdf">DistanceGAN</a>, <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Fu_Geometry-Consistent_Generative_Adversarial_Networks_for_One-Sided_Unsupervised_Domain_Mapping_CVPR_2019_paper.pdf">GCGAN</a></p>
<h3 id="CycleGAN-1"><a href="#CycleGAN-1" class="headerlink" title="CycleGAN"></a>CycleGAN</h3><p>대표적인 unpaired data image-to-image translation으로 cycle-consistency loss을 사용하여 adversairal loss의 문제인 mode collapse 단점을 극복하기 위한 네트워크로, 입력 이미지를 target domain으로 변환하고 입력 및 생성된 이미지의 정확도를 유지하며 두개의 매핑을 동시에 학습하는 네트워크 입니다.</p>
<p>하지만 cycle-consistency의 문제를 완화하기 위해 break the cycle을 시도하고 있으며 대표적인 네트워크가 CUT 입니다.</p>
<h3 id="CouncilGAN"><a href="#CouncilGAN" class="headerlink" title="CouncilGAN"></a>CouncilGAN</h3><p>council loss와 함께 두개 이상의 Generator, Discriminator을 사용합니다.</p>
<p><code>본 논문에서는 CycleGAN, CUT의 장점을 모두 활용합니다. 특히 mutual information maximization을 통해 cycleGAN 아키텍처를 기반으로 한 양방향 unsupervised image-to-image translation이 가능하도록 합니다.</code></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/GAN/" rel="tag"># GAN</a>
              <a href="/tags/Vision/" rel="tag"># Vision</a>
              <a href="/tags/Autoencoder/" rel="tag"># Autoencoder</a>
              <a href="/tags/Uncertainty/" rel="tag"># Uncertainty</a>
              <a href="/tags/Unsupervised-Learning/" rel="tag"># Unsupervised Learning</a>
              <a href="/tags/paper-review/" rel="tag"># paper review</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2021/12/26/MemAE-Memorizing-Normality-to-Detect-Anomaly-Memory-augmented-Deep-Autoencoder-for-Unsupervised-Anomaly-Detection/" rel="prev" title="Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection [MemAE]">
                  <i class="fa fa-chevron-left"></i> Memory-augmented Deep Autoencoder for Unsupervised Anomaly Detection [MemAE]
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/03/13/Adversarial-Latent-Autoencoders-md/" rel="next" title="Adversarial Latent Autoencoders">
                  Adversarial Latent Autoencoders <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">mulkong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.0/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  


















  








  

  
      <script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              const target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    const script = document.createElement('script');
    script.src = '//cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js';
    script.defer = true;
    document.head.appendChild(script);
  } else {
    MathJax.startup.document.state(0);
    MathJax.typesetClear();
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
